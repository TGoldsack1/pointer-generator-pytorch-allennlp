{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["We describe a new training methodology for generative adversarial networks.", "The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses.", "This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024.", "We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10.", "Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator.", "Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation.", "As an additional contribution, we construct a higher-quality version of the CELEBA dataset."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Generative methods that produce novel samples from high-dimensional data distributions, such as images, are finding widespread use, for example in speech synthesis (van den Oord et al., 2016a), image-to-image translation (Zhu et al., 2017; Liu et al., 2017; Wang et al., 2017), and image inpainting (Iizuka et al., 2017).", "Currently the most prominent approaches are autoregressive models (van den Oord et al., 2016b;c), variational autoencoders (VAE) (Kingma & Welling, 2014), and generative adversarial networks (GAN) (Goodfellow et al., 2014).", "Currently they all have significant strengths and weaknesses.", "Autoregressive models \u2013 such as PixelCNN \u2013 produce sharp images but are slow to evaluate and do not have a latent representation as they directly model the conditional distribution over pixels, potentially limiting their applicability.", "VAEs are easy to train but tend to produce blurry results due to restrictions in the model, although recent work is improving this (Kingma et al., 2016).", "GANs produce sharp images, albeit only in fairly small resolutions and with somewhat limited variation, and the training continues to be unstable despite recent progress (Salimans et al., 2016; Gulrajani et al., 2017; Berthelot et al., 2017; Kodali et al., 2017).", "Hybrid methods combine various strengths of the three, but so far lag behind GANs in image quality (Makhzani & Frey, 2017; Ulyanov et al., 2017; Dumoulin et al., 2016).", "Typically, a GAN consists of two networks: generator and discriminator (aka critic).", "The generator produces a sample, e.g., an image, from a latent code, and the distribution of these images should ideally be indistinguishable from the training distribution.", "Since it is generally infeasible to engineer a function that tells whether that is the case, a discriminator network is trained to do the assessment, and since networks are differentiable, we also get a gradient we can use to steer both networks to the right direction.", "Typically, the generator is of main interest \u2013 the discriminator is an adaptive loss function that gets discarded once the generator has been trained.", "There are multiple potential problems with this formulation.", "When we measure the distance between the training distribution and the generated distribution, the gradients can point to more or less random directions if the distributions do not have substantial overlap, i.e., are too easy to tell apart (Arjovsky & Bottou, 2017).", "Originally, Jensen-Shannon divergence was used as a distance metric (Goodfellow et al., 2014), and recently that formulation has been improved (Hjelm et al., 2017) and a number of more stable alternatives have been proposed, including least squares (Mao et al., 2016b), absolute deviation with margin (Zhao et al., 2017), and Wasserstein distance (Arjovsky et al., 2017; Gulrajani\nar X\niv :1\n71 0.", "10 19\n6v 3\n[ cs\n.N E\n] 2\n6 Fe\nb 20\n18\net al., 2017).", "Our contributions are largely orthogonal to this ongoing discussion, and we primarily use the improved Wasserstein loss, but also experiment with least-squares loss.", "The generation of high-resolution images is difficult because higher resolution makes it easier to tell the generated images apart from training images (Odena et al., 2017), thus drastically amplifying the gradient problem.", "Large resolutions also necessitate using smaller minibatches due to memory constraints, further compromising training stability.", "Our key insight is that we can grow both the generator and discriminator progressively, starting from easier low-resolution images, and add new layers that introduce higher-resolution details as the training progresses.", "This greatly speeds up training and improves stability in high resolutions, as we will discuss in Section 2.", "The GAN formulation does not explicitly require the entire training data distribution to be represented by the resulting generative model.", "The conventional wisdom has been that there is a tradeoff between image quality and variation, but that view has been recently challenged (Odena et al., 2017).", "The degree of preserved variation is currently receiving attention and various methods have been suggested for measuring it, including inception score (Salimans et al., 2016), multi-scale structural similarity (MS-SSIM) (Odena et al., 2017; Wang et al., 2003), birthday paradox (Arora & Zhang, 2017), and explicit tests for the number of discrete modes discovered (Metz et al., 2016).", "We will describe our method for encouraging variation in Section 3, and propose a new metric for evaluating the quality and variation in Section 5.", "Section 4.1 discusses a subtle modification to the initialization of networks, leading to a more balanced learning speed for different layers.", "Furthermore, we observe that mode collapses traditionally plaguing GANs tend to happen very quickly, over the course of a dozen minibatches.", "Commonly they start when the discriminator overshoots, leading to exaggerated gradients, and an unhealthy competition follows where the signal magnitudes escalate in both networks.", "We propose a mechanism to stop the generator from participating in such escalation, overcoming the issue (Section 4.2).", "We evaluate our contributions using the CELEBA, LSUN, CIFAR10 datasets.", "We improve the best published inception score for CIFAR10.", "Since the datasets commonly used in benchmarking generative methods are limited to a fairly low resolution, we have also created a higher quality version of the CELEBA dataset that allows experimentation with output resolutions up to 1024 \u00d7 1024 pixels.", "This dataset and our full implementation are available at https://github.com/tkarras/progressive_growing_of_gans, trained networks can be found at https://drive.google.com/open?id=0B4qLcYyJmiz0NHFULTdYc05lX0U along with result images, and a supplementary video illustrating the datasets, additional results, and latent space interpolations is at https://youtu.be/G06dEcZ-QTg."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Our primary contribution is a training methodology for GANs where we start with low-resolution images, and then progressively increase the resolution by adding layers to the networks as visualized in Figure 1.", "This incremental nature allows the training to first discover large-scale structure of the image distribution and then shift attention to increasingly finer scale detail, instead of having to learn all scales simultaneously.", "We use generator and discriminator networks that are mirror images of each other and always grow in synchrony.", "All existing layers in both networks remain trainable throughout the training process.", "When new layers are added to the networks, we fade them in smoothly, as illustrated in Figure 2.", "This avoids sudden shocks to the already well-trained, smaller-resolution layers.", "Appendix A describes structure of the generator and discriminator in detail, along with other training parameters.", "We observe that the progressive training has several benefits.", "Early on, the generation of smaller images is substantially more stable because there is less class information and fewer modes (Odena et al., 2017).", "By increasing the resolution little by little we are continuously asking a much simpler question compared to the end goal of discovering a mapping from latent vectors to e.g.", "10242 images.", "This approach has conceptual similarity to recent work by Chen & Koltun (2017).", "In practice it stabilizes the training sufficiently for us to reliably synthesize megapixel-scale images using WGAN-GP loss (Gulrajani et al., 2017) and even LSGAN loss (Mao et al., 2016b).", "throughout the process.", "Here N \u00d7N refers to convolutional layers operating on N \u00d7 N spatial resolution.", "This allows stable synthesis in high resolutions and also speeds up training considerably.", "One the right we show six example images generated using progressive growing at 1024\u00d7 1024.", "Another benefit is the reduced training time.", "With progressively growing GANs most of the iterations are done at lower resolutions, and comparable result quality is often obtained up to 2\u20136 times faster, depending on the final output resolution.", "The idea of growing GANs progressively is related to the work of Wang et al.", "(2017), who use multiple discriminators that operate on different spatial resolutions.", "That work in turn is motivated by Durugkar et al.", "(2016) who use one generator and multiple discriminators concurrently, and Ghosh et al.", "(2017) who do the opposite with multiple generators and one discriminator.", "Hierarchical GANs (Denton et al., 2015; Huang et al., 2016; Zhang et al., 2017) define a generator and discriminator for each level of an image pyramid.", "These methods build on the same observation as our work \u2013 that the complex mapping from latents to high-resolution images is easier to learn in steps \u2013 but the crucial difference is that we have only a single GAN instead of a hierarchy of them.", "In contrast to early work on adaptively growing networks, e.g., growing neural gas (Fritzke, 1995) and neuro evolution of augmenting topologies (Stanley & Miikkulainen, 2002) that grow networks greedily, we simply defer the introduction of pre-configured layers.", "In that sense our approach resembles layer-wise training of autoencoders (Bengio et al., 2007)."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["GANs have a tendency to capture only a subset of the variation found in training data, and Salimans et al.", "(2016) suggest \u201cminibatch discrimination\u201d as a solution.", "They compute feature statistics not only from individual images but also across the minibatch, thus encouraging the minibatches of generated and training images to show similar statistics.", "This is implemented by adding a minibatch layer towards the end of the discriminator, where the layer learns a large tensor that projects the input activation to an array of statistics.", "A separate set of statistics is produced for each example in a minibatch and it is concatenated to the layer\u2019s output, so that the discriminator can use the statistics internally.", "We simplify this approach drastically while also improving the variation.", "Our simplified solution has neither learnable parameters nor new hyperparameters.", "We first compute the standard deviation for each feature in each spatial location over the minibatch.", "We then average these estimates over all features and spatial locations to arrive at a single value.", "We replicate the value and concatenate it to all spatial locations and over the minibatch, yielding one additional (constant) feature map.", "This layer could be inserted anywhere in the discriminator, but we have found it best to insert it towards the end (see Appendix A.1 for details).", "We experimented with a richer set of statistics, but were not able to improve the variation further.", "In parallel work, Lin et al.", "(2017) provide theoretical insights about the benefits of showing multiple images to the discriminator.", "residual block, whose weight \u03b1 increases linearly from 0 to 1.", "Here 2\u00d7 and 0.5\u00d7 refer to doubling and halving the image resolution using nearest neighbor filtering and average pooling, respectively.", "The toRGB represents a layer that projects feature vectors to RGB colors and fromRGB does the reverse; both use 1 \u00d7 1 convolutions.", "When training the discriminator, we feed in real images that are downscaled to match the current resolution of the network.", "During a resolution transition, we interpolate between two resolutions of the real images, similarly to how the generator output combines two resolutions.", "Alternative solutions to the variation problem include unrolling the discriminator (Metz et al., 2016) to regularize its updates, and a \u201crepelling regularizer\u201d (Zhao et al., 2017) that adds a new loss term to the generator, trying to encourage it to orthogonalize the feature vectors in a minibatch.", "The multiple generators of Ghosh et al.", "(2017) also serve a similar goal.", "We acknowledge that these solutions may increase the variation even more than our solution \u2013 or possibly be orthogonal to it \u2013 but leave a detailed comparison to a later time."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["GANs are prone to the escalation of signal magnitudes as a result of unhealthy competition between the two networks.", "Most if not all earlier solutions discourage this by using a variant of batch normalization (Ioffe & Szegedy, 2015; Salimans & Kingma, 2016; Ba et al., 2016) in the generator, and often also in the discriminator.", "These normalization methods were originally introduced to eliminate covariate shift.", "However, we have not observed that to be an issue in GANs, and thus believe that the actual need in GANs is constraining signal magnitudes and competition.", "We use a different approach that consists of two ingredients, neither of which include learnable parameters."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["We deviate from the current trend of careful weight initialization, and instead use a trivial N (0, 1) initialization and then explicitly scale the weights at runtime.", "To be precise, we set w\u0302i = wi/c, where wi are the weights and c is the per-layer normalization constant from He\u2019s initializer (He et al., 2015).", "The benefit of doing this dynamically instead of during initialization is somewhat subtle, and relates to the scale-invariance in commonly used adaptive stochastic gradient descent methods such as RMSProp (Tieleman & Hinton, 2012) and Adam (Kingma & Ba, 2015).", "These methods normalize a gradient update by its estimated standard deviation, thus making the update independent of the scale of the parameter.", "As a result, if some parameters have a larger dynamic range than others, they will take longer to adjust.", "This is a scenario modern initializers cause, and thus it is possible that a learning rate is both too large and too small at the same time.", "Our approach ensures that the dynamic range, and thus the learning speed, is the same for all weights.", "A similar reasoning was independently used by van Laarhoven (2017)."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["To disallow the scenario where the magnitudes in the generator and discriminator spiral out of control as a result of competition, we normalize the feature vector in each pixel to unit length in the generator after each convolutional layer.", "We do this using a variant of \u201clocal response normaliza-\ntion\u201d (Krizhevsky et al., 2012), configured as bx,y = ax,y/ \u221a 1 N \u2211N\u22121 j=0 (a j x,y)2 + , where = 10\u22128, N is the number of feature maps, and ax,y and bx,y are the original and normalized feature vector in pixel (x, y), respectively.", "We find it surprising that this heavy-handed constraint does not seem to harm the generator in any way, and indeed with most datasets it does not change the results much, but it prevents the escalation of signal magnitudes very effectively when needed."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["In order to compare the results of one GAN to another, one needs to investigate a large number of images, which can be tedious, difficult, and subjective.", "Thus it is desirable to rely on automated methods that compute some indicative metric from large image collections.", "We noticed that existing methods such as MS-SSIM (Odena et al., 2017) find large-scale mode collapses reliably but fail to react to smaller effects such as loss of variation in colors or textures, and they also do not directly assess image quality in terms of similarity to the training set.", "We build on the intuition that a successful generator will produce samples whose local image structure is similar to the training set over all scales.", "We propose to study this by considering the multiscale statistical similarity between distributions of local image patches drawn from Laplacian pyramid (Burt & Adelson, 1987) representations of generated and target images, starting at a low-pass resolution of 16 \u00d7 16 pixels.", "As per standard practice, the pyramid progressively doubles until the full resolution is reached, each successive level encoding the difference to an up-sampled version of the previous level.", "A single Laplacian pyramid level corresponds to a specific spatial frequency band.", "We randomly sample 16384 images and extract 128 descriptors from each level in the Laplacian pyramid, giving us 221 (2.1M) descriptors per level.", "Each descriptor is a 7 \u00d7 7 pixel neighborhood with 3 color channels, denoted by x \u2208 R7\u00d77\u00d73 = R147.", "We denote the patches from level l of the training set and generated set as {xli}2 21 i=1 and {yli}2 21\ni=1, respectively.", "We first normalize {xli} and {yli} w.r.t.", "the mean and standard deviation of each color channel, and then estimate the statistical similarity by computing their sliced Wasserstein distance SWD({xli}, {yli}), an efficiently computable randomized approximation to earthmovers distance, using 512 projections (Rabin et al., 2011).", "Intuitively a small Wasserstein distance indicates that the distribution of the patches is similar, meaning that the training images and generator samples appear similar in both appearance and variation at this spatial resolution.", "In particular, the distance between the patch sets extracted from the lowestresolution 16 \u00d7 16 images indicate similarity in large-scale image structures, while the finest-level patches encode information about pixel-level attributes such as sharpness of edges and noise."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["In this section we discuss a set of experiments that we conducted to evaluate the quality of our results.", "Please refer to Appendix A for detailed description of our network structures and training configurations.", "We also invite the reader to consult the accompanying video (https://youtu.be/G06dEcZ-QTg) for additional result images and latent space interpolations.", "In this section we will distinguish between the network structure (e.g., convolutional layers, resizing), training configuration (various normalization layers, minibatch-related operations), and training loss (WGAN-GP, LSGAN)."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["We will first use the sliced Wasserstein distance (SWD) and multi-scale structural similarity (MSSSIM) (Odena et al., 2017) to evaluate the importance our individual contributions, and also perceptually validate the metrics themselves.", "We will do this by building on top of a previous state-of-theart loss function (WGAN-GP) and training configuration (Gulrajani et al., 2017) in an unsupervised setting using CELEBA (Liu et al., 2015) and LSUN BEDROOM (Yu et al., 2015) datasets in 1282\nresolution.", "CELEBA is particularly well suited for such comparison because the training images contain noticeable artifacts (aliasing, compression, blur) that are difficult for the generator to reproduce faithfully.", "In this test we amplify the differences between training configurations by choosing a relatively low-capacity network structure (Appendix A.2) and terminating the training once the discriminator has been shown a total of 10M real images.", "As such the results are not fully converged.", "Table 1 lists the numerical values for SWD and MS-SSIM in several training configurations, where our individual contributions are cumulatively enabled one by one on top of the baseline (Gulrajani et al., 2017).", "The MS-SSIM numbers were averaged from 10000 pairs of generated images, and SWD was calculated as described in Section 5.", "Generated CELEBA images from these configurations are shown in Figure 3.", "Due to space constraints, the figure shows only a small number of examples for each row of the table, but a significantly broader set is available in Appendix H. Intuitively, a good evaluation metric should reward plausible images that exhibit plenty of variation in colors, textures, and viewpoints.", "However, this is not captured by MS-SSIM: we can immediately see that configuration (h) generates significantly better images than configuration (a), but MS-SSIM remains approximately unchanged because it measures only the variation between outputs, not similarity to the training set.", "SWD, on the other hand, does indicate a clear improvement.", "The first training configuration (a) corresponds to Gulrajani et al.", "(2017), featuring batch normalization in the generator, layer normalization in the discriminator, and minibatch size of 64.", "(b) enables progressive growing of the networks, which results in sharper and more believable output images.", "SWD correctly finds the distribution of generated images to be more similar to the training set.", "Our primary goal is to enable high output resolutions, and this requires reducing the size of minibatches in order to stay within the available memory budget.", "We illustrate the ensuing challenges in (c) where we decrease the minibatch size from 64 to 16.", "The generated images are unnatural, which is clearly visible in both metrics.", "In (d), we stabilize the training process by adjusting the hyperparameters as well as by removing batch normalization and layer normalization (Appendix A.2).", "As an intermediate test (e\u2217), we enable minibatch discrimination (Salimans et al., 2016), which somewhat surprisingly fails to improve any of the metrics, including MS-SSIM that measures output variation.", "In contrast, our minibatch standard deviation (e) improves the average SWD scores and images.", "We then enable our remaining contributions in (f) and (g), leading to an overall improvement in SWD\nand subjective visual quality.", "Finally, in (h) we use a non-crippled network and longer training \u2013 we feel the quality of the generated images is at least comparable to the best published results so far."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Figure 4 illustrates the effect of progressive growing in terms of the SWD metric and raw image throughput.", "The first two plots correspond to the training configuration of Gulrajani et al.", "(2017) without and with progressive growing.", "We observe that the progressive variant offers two main benefits: it converges to a considerably better optimum and also reduces the total training time by about a factor of two.", "The improved convergence is explained by an implicit form of curriculum learning that is imposed by the gradually increasing network capacity.", "Without progressive growing, all layers of the generator and discriminator are tasked with simultaneously finding succinct intermediate representations for both the large-scale variation and the small-scale detail.", "With progressive growing, however, the existing low-resolution layers are likely to have already converged early on, so the networks are only tasked with refining the representations by increasingly smaller-scale effects as new layers are introduced.", "Indeed, we see in Figure 4(b) that the largest-scale statistical similarity curve (16) reaches its optimal value very quickly and remains consistent throughout the rest of the training.", "The smaller-scale curves (32, 64, 128) level off one by one as the resolution is increased, but the convergence of each curve is equally consistent.", "With non-progressive training in Figure 4(a), each scale of the SWD metric converges roughly in unison, as could be expected.", "The speedup from progressive growing increases as the output resolution grows.", "Figure 4(c) shows training progress, measured in number of real images shown to the discriminator, as a function of training time when the training progresses all the way to 10242 resolution.", "We see that progressive growing gains a significant head start because the networks are shallow and quick to evaluate at the beginning.", "Once the full resolution is reached, the image throughput is equal between the two methods.", "The plot shows that the progressive variant reaches approximately 6.4 million images in 96 hours, whereas it can be extrapolated that the non-progressive variant would take about 520 hours to reach the same point.", "In this case, the progressive growing offers roughly a 5.4\u00d7 speedup."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["To meaningfully demonstrate our results at high output resolutions, we need a sufficiently varied high-quality dataset.", "However, virtually all publicly available datasets previously used in GAN literature are limited to relatively low resolutions ranging from 322 to 4802.", "To this end, we created a high-quality version of the CELEBA dataset consisting of 30000 of the images at 1024 \u00d7 1024 resolution.", "We refer to Appendix C for further details about the generation of this dataset.", "Our contributions allow us to deal with high output resolutions in a robust and efficient fashion.", "Figure 5 shows selected 1024 \u00d7 1024 images produced by our network.", "While megapixel GAN results have been shown before in another dataset (Marchesi, 2017), our results are vastly more varied and of higher perceptual quality.", "Please refer to Appendix F for a larger set of result images as well as the nearest neighbors found from the training data.", "The accompanying video shows latent space interpolations and visualizes the progressive training.", "The interpolation works so that we first randomize a latent code for each frame (512 components sampled individually from N (0, 1)), then blur the latents across time with a Gaussian (\u03c3 = 45 frames @ 60Hz), and finally normalize each vector to lie on a hypersphere.", "We trained the network on 8 Tesla V100 GPUs for 4 days, after which we no longer observed qualitative differences between the results of consecutive training iterations.", "Our implementation used an adaptive minibatch size depending on the current output resolution so that the available memory budget was optimally utilized.", "In order to demonstrate that our contributions are largely orthogonal to the choice of a loss function, we also trained the same network using LSGAN loss instead of WGAN-GP loss.", "Figure 1 shows six examples of 10242 images produced using our method using LSGAN.", "Further details of this setup are given in Appendix B."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Figure 6 shows a purely visual comparison between our solution and earlier results in LSUN BEDROOM.", "Figure 7 gives selected examples from seven very different LSUN categories at 2562.", "A larger, non-curated set of results from all 30 LSUN categories is available in Appendix G, and the video demonstrates interpolations.", "We are not aware of earlier results in most of these categories, and while some categories work better than others, we feel that the overall quality is high."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["The best inception scores for CIFAR10 (10 categories of 32 \u00d7 32 RGB images) we are aware of are 7.90 for unsupervised and 8.87 for label conditioned setups (Grinblat et al., 2017).", "The large difference between the two numbers is primarily caused by \u201cghosts\u201d that necessarily appear between classes in the unsupervised setting, while label conditioning can remove many such transitions.", "When all of our contributions are enabled, we get 8.80 in the unsupervised setting.", "Appendix D shows a representative set of generated images along with a more comprehensive list of results from earlier methods.", "The network and training setup were the same as for CELEBA, progression limited to 32 \u00d7 32 of course.", "The only customization was to the WGAN-GP\u2019s regularization term Ex\u0302\u223cPx\u0302 [(||\u2207x\u0302D(x\u0302)||2 \u2212 \u03b3)2/\u03b32].", "Gulrajani et al.", "(2017) used \u03b3 = 1.0, which corresponds to 1-Lipschitz, but we noticed that it is in fact significantly better to prefer fast transitions (\u03b3 = 750) to minimize the ghosts.", "We have not tried this trick with other datasets."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["While the quality of our results is generally high compared to earlier work on GANs, and the training is stable in large resolutions, there is a long way to true photorealism.", "Semantic sensibility and understanding dataset-dependent constraints, such as certain objects being straight rather than curved, leaves a lot to be desired.", "There is also room for improvement in the micro-structure of the images.", "That said, we feel that convincing realism may now be within reach, especially in CELEBA-HQ."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["We would like to thank Mikael Honkavaara, Tero Kuosmanen, and Timi Hietanen for the compute infrastructure.", "Dmitry Korobchenko and Richard Calderwood for efforts related to the CELEBA-HQ dataset.", "Oskar Elek, Jacob Munkberg, and Jon Hasselgren for useful comments."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["A.1 1024\u00d7 1024 NETWORKS USED FOR CELEBA-HQ\nTable 2 shows network architectures of the full-resolution generator and discriminator that we use with the CELEBA-HQ dataset.", "Both networks consist mainly of replicated 3-layer blocks that we introduce one by one during the course of the training.", "The last Conv 1 \u00d7 1 layer of the generator corresponds to the toRGB block in Figure 2, and the first Conv 1 \u00d7 1 layer of the discriminator similarly corresponds to fromRGB.", "We start with 4 \u00d7 4 resolution and train the networks until we have shown the discriminator 800k real images in total.", "We then alternate between two phases: fade in the first 3-layer block during the next 800k images, stabilize the networks for 800k images, fade in the next 3-layer block during 800k images, etc.", "Our latent vectors correspond to random points on a 512-dimensional hypersphere, and we represent training and generated images in [-1,1].", "We use leaky ReLU with leakiness 0.2 in all layers of both networks, except for the last layer that uses linear activation.", "We do not employ batch normalization, layer normalization, or weight normalization in either network, but we perform pixelwise normalization of the feature vectors after each Conv 3\u00d73 layer in the generator as described in Section 4.2.", "We initialize all bias parameters to zero and all weights according to the normal distribution with unit variance.", "However, we scale the weights with a layer-specific constant at runtime as described in Section 4.1.", "We inject the across-minibatch standard deviation as an additional feature map at 4\u00d7 4 resolution toward the end of the discriminator as described in Section 3.", "The upsampling and downsampling operations in Table 2 correspond to 2 \u00d7 2 element replication and average pooling, respectively.", "We train the networks using Adam (Kingma & Ba, 2015) with \u03b1 = 0.001, \u03b21 = 0, \u03b22 = 0.99, and = 10\u22128.", "We do not use any learning rate decay or rampdown, but for visualizing generator output at any given point during the training, we use an exponential running average for the weights of the generator with decay 0.999.", "We use a minibatch size 16 for resolutions 42\u20131282 and then gradually decrease the size according to 2562 \u2192 14, 5122 \u2192 6, and 10242 \u2192 3 to avoid exceeding the available memory budget.", "We use the WGAN-GP loss, but unlike Gulrajani et al.", "(2017), we alternate between optimizing the generator and discriminator on a per-minibatch basis, i.e., we set ncritic = 1.", "Additionally, we introduce a fourth term into the discriminator loss with an extremely\nsmall weight to keep the discriminator output from drifting too far away from zero.", "To be precise, we set L\u2032 = L+ driftEx\u2208Pr [D(x)2], where drift = 0.001.", "A.2 OTHER NETWORKS\nWhenever we need to operate on a spatial resolution lower than 1024\u00d7 1024, we do that by leaving out an appropriate number copies of the replicated 3-layer block in both networks.", "Furthermore, Section 6.1 uses a slightly lower-capacity version, where we halve the number of feature maps in Conv 3 \u00d7 3 layers at the 16 \u00d7 16 resolution, and divide by 4 in the subsequent resolutions.", "This leaves 32 feature maps to the last Conv 3 \u00d7 3 layers.", "In Table 1 and Figure 4 we train each resolution for a total 600k images instead of 800k, and also fade in new layers for the duration of 600k images.", "For the \u201cGulrajani et al.", "(2017)\u201d case in Table 1, we follow their training configuration as closely as possible.", "In particular, we set \u03b1 = 0.0001, \u03b22 = 0.9, ncritic = 5, drift = 0, and minibatch size 64.", "We disable progressive resolution, minibatch stddev, as well as weight scaling at runtime, and initialize all weights using He\u2019s initializer (He et al., 2015).", "Furthermore, we modify the generator by replacing LReLU with ReLU, linear activation with tanh in the last layer, and pixelwise normalization with batch normalization.", "In the discriminator, we add layer normalization to all Conv 3\u00d7 3 and Conv 4\u00d7 4 layers.", "For the latent vectors, we use 128 components sampled independently from the normal distribution.", "B LEAST-SQUARES GAN (LSGAN) AT 1024\u00d7 1024\nWe find that LSGAN is generally a less stable loss function than WGAN-GP, and it also has a tendency to lose some of the variation towards the end of long runs.", "Thus we prefer WGAN-GP, but have also produced high-resolution images by building on top of LSGAN.", "For example, the 10242 images in Figure 1 are LSGAN-based.", "On top of the techniques described in Sections 2\u20134, we need one additional hack with LSGAN that prevents the training from spiraling out of control when the dataset is too easy for the discriminator, and the discriminator gradients are at risk of becoming meaningless as a result.", "We adaptively increase the magnitude of multiplicative Gaussian noise in discriminator as a function of the discriminator\u2019s output.", "The noise is applied to the input of each Conv 3 \u00d7 3 and Conv 4 \u00d7 4 layer.", "There is a long history of adding noise to the discriminator, and it is generally detrimental for the image quality (Arjovsky et al., 2017) and ideally one would never have to do that, which according to our tests is the case for WGAN-GP (Gulrajani et al., 2017).", "The magnitude of noise is determined as 0.2 \u00b7 max(0, d\u0302t \u2212 0.5)2, where d\u0302t = 0.1d + 0.9d\u0302t\u22121 is an exponential moving average of the discriminator output d. The motivation behind this hack is that LSGAN is seriously unstable when d approaches (or exceeds) 1.0."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["In this section we describe the process we used to create the high-quality version of the CELEBA dataset, consisting of 30000 images in 1024 \u00d7 1024 resolution.", "As a starting point, we took the collection of in-the-wild images included as a part of the original CELEBA dataset.", "These images are extremely varied in terms of resolution and visual quality, ranging all the way from 43 \u00d7 55 to 6732 \u00d7 8984.", "Some of them show crowds of several people whereas others focus on the face of a single person \u2013 often only a part of the face.", "Thus, we found it necessary to apply several image processing steps to ensure consistent quality and to center the images on the facial region.", "Our processing pipeline is illustrated in Figure 8.", "To improve the overall image quality, we preprocess each JPEG image using two pre-trained neural networks: a convolutional autoencoder trained to remove JPEG artifacts in natural images, similar in structure to the proposed by Mao et al.", "(2016a), and an adversarially-trained 4x super-resolution network (Korobchenko & Foco, 2017) similar to Ledig et al.", "(2016).", "To handle cases where the facial region extends outside the image, we employ padding and filtering to extend the dimensions of the image as illustrated in Fig.8(c\u2013d).", "We then select an oriented crop rectangle based on the facial landmark annotations included in the\noriginal CELEBA dataset as follows:\nx\u2032 = e1 \u2212 e0 y\u2032 = 1\n2 (e0 + e1)\u2212\n1 2 (m0 +m1)\nc = 1\n2 (e0 + e1)\u2212 0.1 \u00b7 y\u2032\ns = max (4.0 \u00b7 |x\u2032|, 3.6 \u00b7 |y\u2032|) x = Normalize (x\u2032 \u2212 Rotate90(y\u2032)) y = Rotate90(x)\ne0, e1, m0, and m1 represent the 2D pixel locations of the two eye landmarks and two mouth landmarks, respectively, c and s indicate the center and size of the desired crop rectangle, and x and y indicate its orientation.", "We constructed the above formulas empirically to ensure that the crop rectangle stays consistent in cases where the face is viewed from different angles.", "Once we have calculated the crop rectangle, we transform the rectangle to 4096\u00d7 4096 pixels using bilinear filtering, and then scale it to 1024\u00d7 1024 resolution using a box filter.", "We perform the above processing for all 202599 images in the dataset, analyze the resulting 1024\u00d7 1024 images further to estimate the final image quality, sort the images accordingly, and discard all but the best 30000 images.", "We use a frequency-based quality metric that favors images whose power spectrum contains a broad range of frequencies and is approximately radially symmetric.", "This penalizes blurry images as well as images that have conspicuous directional features due to, e.g., visible halftoning patterns.", "We selected the cutoff point of 30000 images as a practical sweet spot between variation and image quality, because it appeared to yield the best results."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Figure 9 shows non-curated images generated in the unsupervised setting, and Table 3 compares against prior art in terms of inception scores.", "We report our scores in two different ways: 1) the highest score observed during training runs (here \u00b1 refers to the standard deviation returned by the inception score calculator) and 2) the mean and standard deviation computed from the highest scores seen during training, starting from ten random initializations.", "Arguably the latter methodology is much more meaningful as one can be lucky with individual runs (as we were).", "We did not use any kind of augmentation with this dataset."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Metz et al.", "(2016) describe a setup where a generator synthesizes MNIST digits simultaneously to 3 color channels, the digits are classified using a pre-trained classifier (0.4% error rate in our case), and concatenated to form a number in [0, 999].", "They generate a total of 25,600 images and count\nhow many of the discrete modes are covered.", "They also compute KL divergence as KL(histogram || uniform).", "Modern GAN implementations can trivially cover all modes at very low divergence (0.05 in our case), and thus Metz et al.", "specify a fairly low-capacity generator and two severely crippled discriminators (\u201cK/2\u201d has \u223c 2000 params and \u201cK/4\u201d only about \u223c 500) to tease out differences between training methodologies.", "Both of these networks use batch normalization.", "As shown in Table 4, using WGAN-GP loss with the networks specified by Metz et al.", "covers much more modes than the original GAN loss, and even more than the unrolled original GAN with the smaller (K/4) discriminator.", "The KL divergence, which is arguably a more accurate metric than the raw count, acts even more favorably.", "Replacing batch normalization with our normalization (equalized learning rate, pixelwise normalization) improves the result considerably, while also removing a few trainable parameters from the discriminators.", "The addition of a minibatch stddev layer further improves the scores, while restoring the discriminator capacity to within 0.5% of the original.", "Progression does not help much with these tiny images, but it does not hurt either."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Figure 10 shows the nearest neighbors found for our generated images.", "Figure 11 gives additional generated examples from CELEBA-HQ.", "We enabled mirror augmentation for all tests using CELEBA and CELEBA-HQ.", "In addition to the sliced Wasserstein distance (SWD), we also quote the recently introduced Fre\u0301chet Inception Distance (FID) (Heusel et al., 2017) computed from 50K images."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Figures 12\u201317 show representative images generated for all 30 LSUN categories.", "A separate network was trained for each category using identical parameters.", "All categories were trained using 100k images, except for BEDROOM and DOG that used all the available data.", "Since 100k images is a very limited amount of training data for most categories, we enabled mirror augmentation in these tests (but not for BEDROOM or DOG)."]}
{"summary_lines": ["They suggest a new method to train GANs.", "They start training them at low resolution (4x4), wait until \"convergence\", then add more convolutions to the existing model to generate and discriminate higher resolutions.", "Each new block of convolutions is slowly blended in, instead of being added from one batch to the next.", "Combined with two new normalization techniques, they get good-looking images at up to 1024x1024 on their new CelebA-HQ dataset (CelebA in high resolution).", "They also suggest a new scoring method based on the approximated Wasserstein distance between real and generated image patches.", "According to that score, their progressive training method improves results significantly.", "What  They suggest a new, progressive training method for GANs.", "The method enables the training of high resolution GANs (1024x1024) that still produce good-looking, diverse images.", "They also introduce two new normalization techniques.", "They also suggest a new method to estimate/score the quality of the generated images.", "They introduce CelebA-HQ, a variation of CelebA containing high resolution images.", "How  Progressive growing/training  They train their GANs resolution by resolution, starting with 4x4 and going up to 1024x1024 (a bit similar to LAPGAN).", "Visualization:  Initially, their generator produces 4x4 images and the discriminator receives 4x4 images.", "Once training at 4x4 does not improve any more (measured by their new score, see below), they add an upscaling module (to 8x8) to the generator and add a downscaling one to the discriminator.", "They don't switch to the added convolutions instantly/suddenly, but give the model a grace period during which the upscaled features are computed from (1-alpha)*A + alpha*B, where A are the features after just upscaling, B are the features after upscaling AND the convolutions and alpha is the overlay factor, which is gradually increased over time.", "This is done for both the generator and the discriminator and at all resolutions.", "Visualization:  Note that all layers are always trained (after they were added to the models).", "Training for the earlier layers does not stop.", "Training in this way focuses most of the computation on the earlier resolutions.", "It also seems to increase stability, as the model does not have to learn all features of all resolutions at the same time.", "Minibatch Standard Deviation  They try to improve diversity by adding a method very similar to minibatch discrimination.", "They compute the standard deviation of each feature per spatial location (for one of the disciminator's last layers).", "They do this per example in each minibatch, resulting in B*H*W*C standard deviations.", "(B = batch size, H = height, W = width, C = channels/filters)  They average these values to one value, then replicate them to size H*W and concatenate that to the layer's output.", "This adds a channel with one constant value to each example in the minibatch.", "The value is the same for all examples.", "Equalized Learning Rate  They use Adam for their training.", "Adam updates weights roughly based on mean(gradient)/variance(gradient) (per weight).", "They argue that this has the downside of equalizing all weight's stepsizes.", "But some weights might require larger stepsizes and other smaller ones (large/small \"dynamic range\").", "As a result, the learning rate will be too small for some weights and too large for others.", "To evade this problem, they first stop using modern weight initialization techniques and instead simply sample weights from the standard normal distribution N(0,1).", "Then, they rescale each weight w_i continuously during runtime to w_i/c, where c is the per-layer normalization from He's initializer.", "(TODO exact formula for c?)", "(This looks an aweful lot like weight normalization .)", "Using simpler weight initialization equalizes the dynamic range of parameters.", "Doing the normalization then fixes problems related to the simpler weight initialization.", "Pixelwise Feature Vector Normalization in the Generator  They argue that collapses in GANs come from the discriminator making some temporary error, leading to high gradients, leading to bad outputs of the generator, leading to more problems in the discriminator and ultimately making both spiral out of control.", "They fix this by normalizing feature vectors in the generator, similar to local response normalization.", "They apply the following equation in the generator (per spatial location (x, y) with N = number of filters):  Scoring Images  They suggest a new method to score images generated by the generator.", "They perform the following steps:  Sample 16384 images from the generator and the dataset.", "Build a Laplacian Pyramid of each image.", "It begins at a 16x16 resolution of the image and progressively doubles that until the final image resolution.", "Each level of the pyramid only contains the difference between the sum of the previous scales and the final image (i.e. each step is a difference image, containing a frequency band).", "Sample per image 128 7x7 neighbourhoods/patches (randomly?)", "from each pyramid level.", "Per image set (generator/real) and pyramid level, compute the mean and standard deviations of each color channels of the sampled patches.", "Normalize each patch with respect to the computed means and standard deviations.", "Use Sliced Wasserstein Distance (SWD) to compute the similarity between the image sets (generator/real).", "The result is one value.", "Lower values are better.", "CelebA-HQ  They derive from CelebA images a new dataset containing 30k 1024x1024 images of celebrity faces.", "They use a convolutional autoencoder to remove JPEG artifacts from the CelebA images.", "They use an adversarially-trained superresolution model to upscale the images.", "They crop faces from the dataset based on their facial landmarks, so that each final face has a normalized position and rotation.", "They rescale the images to 1024x1024 using bilinear sampling and box filters.", "They manually select the 30k best looking images.", "Other stuff  They use Adam for training (alpha=0.001, beta1=0, beta2=0.99).", "They use the WGAN-WP method for training, but LSGAN also works.", "They set gamma to 750 (from 1) for CIFAR-10, incentivizing fast transitions.", "They also add regularization loss on the discriminator, punishing outputs that are very far away from 0.", "Their model for CelebA-HQ training is similar to a standard DCGAN model.", "The generator uses two convolutions after each upscaling, the discriminator analogously two convolutions after each downscaling.", "They start with 512 filters in the generator and end in 16 (before the output) - same for the discriminator.", "They use leaky ReLUs in the generator and discriminator.", "They remove batch normalization everywhere.", "Results  Scores  Results, according to their new scoring measure (Sliced Wasserstein Distance) and MS-SSIM measure:  So progressive growing (b) significantly improves results.", "Same -- to a smaller degree -- for minibatch standard deviation (e), equalized learning rate (f) and pixelwise normalization (g).", "Minibatch discrimination worsened the results.", "Using small batch sizes also worsened the results.", "In (d) they \"adjusted the hyperparameters\" (??)", "and removed batch normalization.", "They generate 1024x1024 CelebA images, while maintaining pixelwise quality compared to previous models.", "They achieve an Inception Score of 8.80 on CIFAR-10.", "Images look improved.", "CelebA-HQ example results:  LSUN dining room, horse, kitchen, churches:"], "article_lines": ["Figure 18 shows larger collections of images corresponding to the non-converged setups in Table 1.", "The training time was intentionally limited to make the differences between various methods more visible."]}
